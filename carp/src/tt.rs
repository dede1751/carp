use std::{
    mem::{size_of, transmute},
    sync::atomic::{AtomicU64, Ordering},
};

use crate::search_params::*;
use chess::{moves::Move, zobrist::ZHash};

/// TTFlag: determines the type of eval stored in the field
#[repr(u8)]
#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Debug, Hash, Default)]
pub enum TTFlag {
    #[default]
    Upper, // Upper bound, generated by Fail-Low
    Lower, // Lower bound, generated by Fail-High (Beta cutoff)
    Exact, // Exact bound, generated by PV nodes
}

/// TTEntry: uncompressed external representation of tt entries
///
/// Compresses to 128b, every single one is used.
/// Mate scores are normalized within the tt for retrieval at different plies: within the tree, we
/// normalize them to the root-distance, while in the tt they are normalized to node-distance.
///
/// 00000000 00000000 00000000 00000000 00000000 00000000 00000000 01111111 -- AGE
/// 00000000 00000000 00000000 00000000 00000000 00000000 00111111 10000000 -- DEPTH
/// 00000000 00000000 00000000 00000000 00000000 00000000 11000000 00000000 -- FLAG
/// 00000000 00000000 00000000 00000000 11111111 11111111 00000000 00000000 -- MOVE
/// 00000000 00000000 11111111 11111111 00000000 00000000 00000000 00000000 -- STATIC EVAL
/// 11111111 11111111 00000000 00000000 00000000 00000000 00000000 00000000 -- SEARCH VALUE
#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Debug, Hash, Default)]
pub struct TTEntry {
    key: u64,        // 64b
    age: u8,         //  7b
    depth: u8,       //  7b
    flag: TTFlag,    //  2b
    best_move: Move, // 16b
    eval: i16,       // 16b
    value: i16,      // 16b
}

// Offsets for the data fields
const DEPTH_OFFSET: u64 = 7;
const FLAG_OFFSET: u64 = 14;
const MOVE_OFFSET: u64 = 16;
const EVAL_OFFSET: u64 = 32;
const VALUE_OFFSET: u64 = 48;

// Masks for the data fields
const AGE_MASK: u64 = 0x7F;
const DEPTH_MASK: u64 = 0x3F80;
const FLAG_MASK: u64 = 0xC000;
const MOVE_MASK: u64 = 0xFFFF0000;
const EVAL_MASK: u64 = 0xFFFF00000000;

/// Convert from external root-distance to internal node-distance
fn to_tt(value: Eval, ply: usize) -> i16 {
    if value >= MATE_IN_PLY {
        (value + ply as Eval) as i16
    } else if value <= -MATE_IN_PLY {
        (value - ply as Eval) as i16
    } else {
        value as i16
    }
}

/// Convert from internal node-distance to external root-distance
fn to_search(value: Eval, ply: usize) -> Eval {
    let ply = ply as Eval;

    if value >= MATE_IN_PLY {
        value - ply
    } else if value <= -MATE_IN_PLY {
        value + ply
    } else {
        value
    }
}

impl TTEntry {
    /// Returns entry depth
    pub fn get_depth(self) -> usize {
        self.depth as usize
    }

    /// Returns entry flag
    pub fn get_flag(self) -> TTFlag {
        self.flag
    }

    /// Returns best move
    pub fn get_move(self) -> Option<Move> {
        if self.best_move != Move::NULL {
            Some(self.best_move)
        } else {
            None
        }
    }

    /// Gets the static evaluation of the position
    pub fn get_eval(self) -> Eval {
        self.eval as Eval
    }

    /// Gets search evaluation while normalizing mate scores
    pub fn get_value(self, ply: usize) -> Eval {
        to_search(self.value as Eval, ply)
    }
}

/// Actual TTEntry, compressed down to 16B and split in two atomic entries
/// Since entries split key and data, we use a XOR trick to avoid concurrency problems where the two
/// fields are modified simultaneously. This ensures with a 16-bit checksum that the data is correctly
/// associated to the key.
/// https://www.chessprogramming.org/Shared_Hash_Table
#[derive(Debug, Default)]
struct AtomicField {
    key: AtomicU64,
    data: AtomicU64,
}

/// Convert from external field to compressed internal
impl From<TTEntry> for (u64, u64) {
    fn from(field: TTEntry) -> Self {
        let data: u64 = field.age as u64
            | (field.depth as u64) << DEPTH_OFFSET
            | (field.flag as u64) << FLAG_OFFSET
            | (field.best_move.0 as u64) << MOVE_OFFSET
            | (field.eval as u16 as u64) << EVAL_OFFSET
            | (field.value as u16 as u64) << VALUE_OFFSET;

        (field.key ^ data, data)
    }
}

/// Convert from compressed internal to external
impl From<(u64, u64)> for TTEntry {
    fn from((key, data): (u64, u64)) -> Self {
        Self {
            key: key ^ data,
            age: (data & AGE_MASK) as u8,
            depth: ((data & DEPTH_MASK) >> DEPTH_OFFSET) as u8,
            flag: unsafe { transmute(((data & FLAG_MASK) >> FLAG_OFFSET) as u8) },
            best_move: Move(((data & MOVE_MASK) >> MOVE_OFFSET) as u16),
            eval: ((data & EVAL_MASK) >> EVAL_OFFSET) as i16,
            value: (data >> VALUE_OFFSET) as i16,
        }
    }
}

impl AtomicField {
    /// Atomic read checking that the field contents match the checksum
    fn read(&self, hash: ZHash) -> Option<TTEntry> {
        let checksum = hash.0;
        let key = self.key.load(Ordering::SeqCst);
        let data = self.data.load(Ordering::SeqCst);

        if key ^ checksum == data {
            Some(TTEntry::from((key, data)))
        } else {
            None
        }
    }

    /// Simple Atomic read, possibly returning mismatching Key and Data
    fn read_unchecked(&self) -> TTEntry {
        let key = self.key.load(Ordering::SeqCst);
        let data = self.data.load(Ordering::SeqCst);

        TTEntry::from((key, data))
    }

    /// Atomic write to table from a tt field struct
    fn write(&self, entry: TTEntry) {
        let (key, data) = entry.into();

        self.key.store(key, Ordering::SeqCst);
        self.data.store(data, Ordering::SeqCst);
    }
}

/// Main transposition table with 16B atomic entries
pub struct TT {
    table: Vec<AtomicField>,
    age: u8,
}

// Default to 16 MiB size
impl Default for TT {
    fn default() -> Self {
        let mut tt = Self {
            table: Vec::new(),
            age: 0,
        };
        tt.resize(Self::DEFAULT_SIZE);

        tt
    }
}

impl TT {
    pub const DEFAULT_SIZE: usize = 16;

    /// Get a key that wraps around the table size, avoiding using Modulo.
    /// https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/
    fn get_key(&self, hash: ZHash) -> usize {
        let key = hash.0 as u128;
        let len = self.table.len() as u128;

        ((key * len) >> 64) as usize
    }

    /// Resize the tt to the given size in MiB
    pub fn resize(&mut self, mb_size: usize) {
        let new_size = (mb_size << 20) / size_of::<AtomicField>();
        self.table.resize_with(new_size, AtomicField::default);
    }

    /// Reset the tt to empty entries
    pub fn clear(&mut self) {
        self.age = 0;
        self.table
            .iter_mut()
            .for_each(|entry| *entry = AtomicField::default());
    }

    /// Increase current age. Entries with older age will be overwritten more easily.
    /// Age is kept to 7 bits to fit in the data field
    pub fn increment_age(&mut self) {
        self.age = (self.age + 1) & 0b01111111; // 7 bit age
    }

    /// Prefetch a cache line containing the entry for the given hash
    /// Implementation from Viridithas
    pub fn prefetch(&self, hash: ZHash) {
        #[cfg(target_arch = "x86_64")]
        unsafe {
            use std::arch::x86_64::{_mm_prefetch, _MM_HINT_T0};

            // get a reference to the entry in the table:
            let tt_index = self.get_key(hash);
            let entry = self.table.get_unchecked(tt_index);

            // prefetch the entry:
            _mm_prefetch((entry as *const AtomicField).cast::<i8>(), _MM_HINT_T0);
        }
    }

    /// Probe tt for entry
    /// UB: so long and we use the wrapped key from TT::get_key, we are guaranteed to be within bounds
    pub fn probe(&self, hash: ZHash) -> Option<TTEntry> {
        unsafe { self.table.get_unchecked(self.get_key(hash)).read(hash) }
    }

    /// Insert entry in appropriate tt field.
    /// The replacement policy is similar to Stockfish's, mostly favoring Exact entries or entries
    /// from different positions, and otherwise discriminating based on depth.
    /// We also use entry aging on top of that.
    #[rustfmt::skip]
    #[allow(clippy::too_many_arguments)]
    pub fn insert(
        &self,
        hash: ZHash,
        flag: TTFlag,
        mut best_move: Move,
        eval: Eval,
        value: Eval,
        depth: usize,
        ply: usize,
        pv: bool,
    ) {
        let old_slot = unsafe { self.table.get_unchecked(self.get_key(hash)) };
        let old  = old_slot.read_unchecked();
        let same_position = hash.0 == old.key;

        if  self.age != old.age // always replace entries with a different age
            || !same_position
            || flag == TTFlag::Exact
            || depth + TT_REPLACE_OFFSET + 2 * usize::from(pv) > old.depth as usize
        {
            // Don't overwrite best moves with null moves
            if best_move == Move::NULL && same_position {
                best_move = old.best_move;
            }

            old_slot.write(TTEntry {
                key: hash.0,
                age: self.age,
                depth: depth as u8,
                flag,
                best_move,
                eval: eval as i16,
                value: to_tt(value, ply),
            });
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tt_init() {
        let mut tt = TT::default();
        tt.resize(1); // 1 MiB table -> 2^20 / 2^4 = 65536

        assert_eq!(16, size_of::<AtomicField>());
        assert_eq!(65536, tt.table.len());
    }

    #[test]
    fn test_tt_insert() {
        let tt = TT::default();
        let z = ZHash(0);

        tt.insert(z, TTFlag::Exact, Move(1), 100, 100, 1, 0, false); // insert in empty field
        tt.insert(z, TTFlag::Exact, Move(1), 100, 100, 12, 0, false); // replace
        tt.insert(z, TTFlag::Upper, Move(1), 100, 100, 1, 0, false); // do not replace

        let target1 = tt.probe(z).unwrap();
        let target2 = tt.probe(ZHash(8));

        assert_eq!(12, target1.get_depth());
        assert!(target2.is_none());
    }

    #[test]
    fn test_tt_collision() {
        let mut tt = TT::default();
        tt.resize(1);

        tt.insert(ZHash(0), TTFlag::Exact, Move::NULL, 100, 100, 1, 0, false); // insert field 1
        tt.insert(ZHash(1), TTFlag::Exact, Move::NULL, 100, 100, 2, 0, false); // insert field 2 in same slot as field 1, replacing it

        let new = tt.probe(ZHash(0)); // check no match on first hash
        assert!(new.is_none());
    }
}
